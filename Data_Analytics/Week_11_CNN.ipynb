{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week_11_CNN.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"VskMijOr0wOe"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F              # funntioncal module\n","from torchvision import transforms, datasets # torchvision으로부터 dataset import"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M-BohvQ4k1BE"},"source":["## CIFAR-10 MLP & CNN\n"]},{"cell_type":"code","metadata":{"id":"UOEM8HG9200q"},"source":["if torch.cuda.is_available():\n","    DEVICE = torch.device('cuda')\n","else:\n","    DEVICE = torch.device('cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxgCYme9hz_D"},"source":["# hyper parameter \n","\n","BATCH_SIZE = 32\n","EPOCHS = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4XNzmNfu_3L"},"source":["train_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n","                                  train = True,\n","                                  download = True,\n","                                  transform = transforms.ToTensor())\n","\n","test_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n","                                train = False,\n","                                transform = transforms.ToTensor())\n","\n","# train / test dataset -> tensor 형태로 불러옴 -> 활용할 수 있는 형태로 변환 data loader \n","# batch_size 32개씩 묶어서 학습함\n","train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n","                                            batch_size = BATCH_SIZE,\n","                                            shuffle = True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n","                                          batch_size = BATCH_SIZE,\n","                                          shuffle = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmEw9Vk5mdv6"},"source":["# data size check \n","# train_X -> batch_size때문에 32개씩 묶여 있고, RGB 형태라 channel이 3개, w * h = 32 * 32 \n","# train_y -> label, 32개씩 묶은 data에 대한 결과값이 들어있음 \n","for (X_train, y_train) in train_loader:\n","    print('X_train:', X_train.size(), 'type:', X_train.type())\n","    print('y_train:', y_train.size(), 'type:', y_train.type())\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r0u13o66meWm"},"source":["# data 일부 출력\n","# 10개의 class로 이루어진 data set \n","pltsize = 1\n","plt.figure(figsize=(10 * pltsize, pltsize))\n","\n","for i in range(10):\n","    plt.subplot(1, 10, i + 1)\n","    plt.axis('off')\n","    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n","    plt.title('Class: ' + str(y_train[i].item()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qnW_8-u1iF94"},"source":["### CIFAR - MLP"]},{"cell_type":"code","metadata":{"id":"bCjW11cUncIX"},"source":["# image로 부터 classification 하는 MLP \n","class MLP(nn.Module):\n","    def __init__(self):\n","        # module에 있는 property를 받고, fcl를 3개 정도 정의 \n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(32 * 32 * 3, 512) # w, h, c, 512개의 output dim으로 도출 \n","        self.fc2 = nn.Linear(512, 256)         # 512 dim -> 256 dim \n","        self.fc3 = nn.Linear(256, 10)          # 256 dim -> 10 label, 분류를 위한 layer  \n","\n","    def forward(self, x):\n","        # forward propagation \n","        x = x.view(-1, 32 * 32 * 3)  # 1D 로 모두 flatten -> 이것 때문에 MLP에서는 image classification의 정확도가 떨어짐 \n","        x = self.fc1(x)               \n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        x = F.log_softmax(x, dim = 1) # Classification\n","        return x "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3RkCQRXoYGl"},"source":["# optimizer -> Adam \n","# loss function -> CrossEntropyLoss로 정의 \n","model = MLP().to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PlWzNa1Rodve"},"source":["# training 정의 \n","def train(model, train_loader, optimizer, log_interval):\n","    model.train()\n","    for batch_idx, (image, label) in enumerate(train_loader):\n","        # image, label을 GPU를 사용한다면 GPU에 맞는 데이터로 변형 \n","        image = image.to(DEVICE)\n","        label = label.to(DEVICE)\n","        # optimizer 초기화\n","        # image를 model에 넣음으로써 output 도출 \n","        # output으로부터 loss 계산 \n","        # 각각에 해당하는 backward 과정을 통해서 gradient 값 할당, update (optimizer.step()) \n","        optimizer.zero_grad()\n","        output = model(image)\n","        loss = criterion(output, label)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % log_interval == 0:\n","            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n","                epoch, batch_idx * len(image), \n","                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n","                loss.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aCH8SooSlLjS"},"source":["def evaluate(model, test_loader):\n","    model.eval()\n","    # test_loss와 correct 0으로 정의 \n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for image, label in test_loader:\n","            image = image.to(DEVICE)\n","            label = label.to(DEVICE)\n","            output = model(image)\n","            # output으로부터 loss와 관련된 정확도(correct)를 계산하는 형태로 정의 \n","            test_loss += criterion(output, label).item()\n","            prediction = output.max(1, keepdim = True)[1]\n","            correct += prediction.eq(label.view_as(prediction)).sum().item()\n","    \n","    test_loss /= len(test_loader.dataset)\n","    test_accuracy = 100. * correct / len(test_loader.dataset)\n","    return test_loss, test_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUvM68hHolNf"},"source":["# 10번의 epoch에 대한 train / test 진행 \n","# 정확도는 48% 정도\n","for epoch in range(1, EPOCHS + 1):\n","    train(model, train_loader, optimizer, log_interval = 200)\n","    test_loss, test_accuracy = evaluate(model, test_loader)\n","    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n","        epoch, test_loss, test_accuracy))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tr1Q8amEmrnv"},"source":["### CIFAR - CNN"]},{"cell_type":"code","metadata":{"id":"8zHOMYlxv_oO"},"source":["# conv block 2(2d Convolution layer), fcl 3개로 정의 \n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        # conv1 = input 3, output 8 channels, kernel 3, padding 1\n","        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding = 1)\n","        # conv2 = input 8, output 16 channels, kernet 3, padding 1\n","        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size=3, padding=1)\n","        # pool = kernel 2, stride 2\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        # fc layer 3 = input, 64, 32, 10\n","        self.fc1 = nn.Linear(8 * 8 * 16, 64) # 64로 flatten \n","        self.fc2 = nn.Linear(64, 32)         # 32로 축소 (반절로 축소) \n","        self.fc3 = nn.Linear(32, 10)         # 10개의 label로 classification \n","    \n","    def forward(self, x):\n","        # 1 conv Block -> reNet은 tanh activation function을 이용함 \n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        # 2 conv Block \n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        # fcl에 연결하기 위한 1D flatten \n","        x = x.view(-1, 8 * 8 * 16)\n","        # 3개의 fcl \n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        x = F.log_softmax(x) # classification \n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yLNAIgaTP4vJ"},"source":["model = CNN().to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FHX_T8JpP7pR"},"source":["def train(model, train_loader, optimizer, log_interval):\n","    model.train()\n","    for batch_idx, (image, label) in enumerate(train_loader):\n","        image = image.to(DEVICE)\n","        label = label.to(DEVICE)\n","        optimizer.zero_grad()\n","        output = model(image)\n","        loss = criterion(output, label)\n","        loss.backward()  # gradient 할당 \n","        optimizer.step() # gradient update \n","\n","        if batch_idx % log_interval == 0:\n","            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n","                epoch, batch_idx * len(image), \n","                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n","                loss.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"35_e-3LwQVcn"},"source":["def evaluate(model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for image, label in test_loader:\n","            image = image.to(DEVICE)\n","            label = label.to(DEVICE)\n","            output = model(image)\n","            test_loss += criterion(output, label).item()\n","            prediction = output.max(1, keepdim = True)[1]\n","            correct += prediction.eq(label.view_as(prediction)).sum().item()\n","    \n","    test_loss /= len(test_loader.dataset)\n","    test_accuracy = 100. * correct / len(test_loader.dataset)\n","    return test_loss, test_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HezHz8TMQo6l"},"source":["# correct -> 62.69%, 15% 정도 증가 \n","for epoch in range(1, EPOCHS + 1):\n","    train(model, train_loader, optimizer, log_interval = 200)\n","    test_loss, test_accuracy = evaluate(model, test_loader)\n","    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n","        epoch, test_loss, test_accuracy))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AvV3n7skoIv0"},"source":["### CIFAR - ResNet"]},{"cell_type":"code","metadata":{"id":"vvnDTVp6olvE"},"source":["class BasicBlock(nn.Module):\n","    def __init__(self, in_planes, planes, stride = 1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size = 3, stride = stride, padding = 1, bias = False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride = 1, padding = 1, bias = False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        \n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, planes, kernel_size = 1, stride = stride, bias = False),\n","                nn.BatchNorm2d(planes))\n","    \n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","    \n","class ResNet(nn.Module):\n","    def __init__(self, num_classes = 10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 16\n","        \n","        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1, bias = False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.layer1 = self._make_layer(16, 2, stride = 1)\n","        self.layer2 = self._make_layer(32, 2, stride = 2)\n","        self.layer3 = self._make_layer(64, 2, stride = 2)\n","        self.linear = nn.Linear(64, num_classes)\n","        \n","    def _make_layer(self, planes, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks  - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(BasicBlock(self.in_planes, planes, stride))\n","            self.in_planes = planes\n","        return nn.Sequential(*layers)\n","    \n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = F.avg_pool2d(out, 8)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P3t9neuZomnv"},"source":["model = ResNet().to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"adQinG1hopV8"},"source":["def train(model, train_loader, optimizer, log_interval):\n","    model.train()\n","    for batch_idx, (image, label) in enumerate(train_loader):\n","        image = image.to(DEVICE)\n","        label = label.to(DEVICE)\n","        optimizer.zero_grad()\n","        output = model(image)\n","        loss = criterion(output, label)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % log_interval == 0:\n","            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n","                epoch, batch_idx * len(image), \n","                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n","                loss.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"00kS545Jor82"},"source":["def evaluate(model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for image, label in test_loader:\n","            image = image.to(DEVICE)\n","            label = label.to(DEVICE)\n","            output = model(image)\n","            test_loss += criterion(output, label).item()\n","            prediction = output.max(1, keepdim = True)[1]\n","            correct += prediction.eq(label.view_as(prediction)).sum().item()\n","    \n","    test_loss /= len(test_loader.dataset)\n","    test_accuracy = 100. * correct / len(test_loader.dataset)\n","    return test_loss, test_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hZeCacvEotmt"},"source":["for epoch in range(1, EPOCHS + 1):\n","    train(model, train_loader, optimizer, log_interval = 200)\n","    test_loss, test_accuracy = evaluate(model, test_loader)\n","    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n","        epoch, test_loss, test_accuracy))"],"execution_count":null,"outputs":[]}]}