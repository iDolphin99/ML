{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5A1Rots52MU5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoHV_pc0AusC"
   },
   "source": [
    "## RNN with a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8IrSaqim2RCM"
   },
   "outputs": [],
   "source": [
    "# 관련 hyper parameter를 정의 \n",
    "# hidden state의 dimension, size -> HIDDEN_DIM\n",
    "HIDDEN_DIM = 35\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "t8BT2CWM2cU7"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OSTLlt5k2sOh"
   },
   "outputs": [],
   "source": [
    "# input으로 활용할 string \n",
    "string = \"hello pytorch and data analytics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Tk1PgbXb3fr8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input에 대해서 one-hot encoding을 진행하기 위해 관련된 alphabet, 공백, .을 정의할 필요가 있음\n",
    "# char_list -> string에 필요한 character를 넣어주면 됨 \n",
    "# 01-> character 나 input에 대해서 start / end 를 구분해주기 위해서 넣어줌  \n",
    "chars = \"abcdefghijklmnopqrstuvwxyz .01\"\n",
    "char_list = [i for i in chars]\n",
    "n_letters = len(char_list)\n",
    "n_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BsxIdHCG3kCt"
   },
   "outputs": [],
   "source": [
    "# string -> one-hot encodding \n",
    "def string_to_onehot(string):\n",
    "    start = np.zeros(shape = n_letters, dtype = int)\n",
    "    end = np.zeros(shape = n_letters, dtype = int)\n",
    "\n",
    "    start[-2] = 1 # 0에 해당하는 위치에 1 -> 첫번째 vector는 start를 알려줌 \n",
    "    end[-1] = 1   # 1에 해당하는 위치에 1 -> 마지막 vector는 end를 알려줌  \n",
    "\n",
    "    # 각각의 character가 위치하는 부분에 0대신에 1을 채워주는 one-hot encodding  \n",
    "    for i in string:\n",
    "        idx = char_list.index(i)\n",
    "        zero = np.zeros(shape = n_letters, dtype = int)\n",
    "        zero[idx] = 1\n",
    "        start = np.vstack([start, zero]) # vstack -> 두 개의 배열을 위 아래로 합쳐줌  \n",
    "    output = np.vstack([start, end])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RT4kKYRi4Ocg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_onehot(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gPIUsEBV2MQ3"
   },
   "outputs": [],
   "source": [
    "# onehot -> string 하는 deccoding \n",
    "def onehot_to_string(onehot):\n",
    "    onehot_value = torch.Tensor.numpy(onehot)\n",
    "    return char_list[onehot_value.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_sj0QMsH2MIu"
   },
   "outputs": [],
   "source": [
    "# RNN class 정의 \n",
    "# torch에 있는 neural network module을 상속받아서 사용 \n",
    "class RNN(nn.Module):\n",
    "    # 속성 정의, 생성자 \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.input2hidden = nn.Linear(input_size, hidden_size)   # input에 해당하는 것을 받아서 hidden을 output \n",
    "        self.hidden2hidden = nn.Linear(hidden_size, hidden_size) # 이전의 hidden을 받아서 현재 hidden을 output \n",
    "        self.hidden2output = nn.Linear(hidden_size, output_size) # 최종적으로 완성된 hideen을 받아서 output\n",
    "        self.act_fn = nn.Tanh() # actication layer, hyperbolic tan\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.act_fn(self.input2hidden(input) + self.hidden2hidden(hidden)) # 현재 input + 지금까지의 hidden = 현재 hidden\n",
    "        output = self.hidden2output(hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    # hidden vector에 대해서 초기화 function \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "hoDJ1uvE7G4P"
   },
   "outputs": [],
   "source": [
    "# input -> embedding 된 size 30, output 동일\n",
    "rnn = RNN(n_letters, HIDDEN_DIM, n_letters)#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "23--JfwD7axN"
   },
   "outputs": [],
   "source": [
    "# loss_fun, optimizer 정의 \n",
    "loss_func = nn.MSELoss().to(device)\n",
    "optimizer_rnn = torch.optim.Adam(rnn.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "QYbiDE7e7zgV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of RNN(\n",
       "  (input2hidden): Linear(in_features=30, out_features=35, bias=True)\n",
       "  (hidden2hidden): Linear(in_features=35, out_features=35, bias=True)\n",
       "  (hidden2output): Linear(in_features=35, out_features=30, bias=True)\n",
       "  (act_fn): Tanh()\n",
       ")>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "W4dFUSgp8I54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0123, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\n",
    "# one-hot 형태의 input을 가지고 training 시작 \n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    # optimizer, hidden 초기화 \n",
    "    optimizer_rnn.zero_grad()\n",
    "    hidden = rnn.init_hidden()\n",
    "    total_loss = 0\n",
    "\n",
    "    # input은 특정 character -> 그 다음 target character  \n",
    "    # input, target에 해당하는 one-hot vector 모두 포함 \n",
    "    # forward를 통해서 나오는 hidden과 output\n",
    "    # forward를 통해 나온 output과 실제 값 target과의 차이를 통해 loss 계산 \n",
    "    for j in range(one_hot.size()[0]-1):\n",
    "        input_ = one_hot[j:j+1, :]#.to(device)\n",
    "        target = one_hot[j+1]#.to(device)\n",
    "        output, hidden = rnn.forward(input_, hidden)\n",
    "        loss = loss_func(output.view(-1), target.view(-1))\n",
    "        total_loss += loss\n",
    "\n",
    "    total_loss.backward() \n",
    "    optimizer_rnn.step()\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "luZcsFpB9EA7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello pytorch and data an tn  n t\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델이 text를 잘 generation 하는가? \n",
    "# 단순히 start token을 넣어주면 그 자리에 있는 있는 string이 나와야 함 \n",
    "start_tkn = torch.zeros(1, n_letters)\n",
    "start_tkn[:, -2] = 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    hidden = rnn.init_hidden()\n",
    "    input_ = start_tkn#.to(device)\n",
    "    output_string = \"\"\n",
    "\n",
    "    for i in range(len(string)):\n",
    "        output, hidden = rnn.forward(input_, hidden)\n",
    "        output_string += onehot_to_string(output.data)\n",
    "        input_ = output\n",
    "\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bo4bJdC7Azdi"
   },
   "source": [
    "## RNN and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "YHO2B1thAPOA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-11-29 08:26:50--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "WARNING: cannot verify raw.githubusercontent.com's certificate, issued by 'CN=DigiCert SHA2 High Assurance Server CA,OU=www.digicert.com,O=DigiCert Inc,C=US':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: './input.txt'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4%  822K 1s\n",
      "    50K .......... .......... .......... .......... ..........  9% 2.91M 1s\n",
      "   100K .......... .......... .......... .......... .......... 13% 6.95M 1s\n",
      "   150K .......... .......... .......... .......... .......... 18% 9.66M 0s\n",
      "   200K .......... .......... .......... .......... .......... 22% 8.18M 0s\n",
      "   250K .......... .......... .......... .......... .......... 27% 7.81M 0s\n",
      "   300K .......... .......... .......... .......... .......... 32% 4.54M 0s\n",
      "   350K .......... .......... .......... .......... .......... 36% 40.4M 0s\n",
      "   400K .......... .......... .......... .......... .......... 41% 47.5M 0s\n",
      "   450K .......... .......... .......... .......... .......... 45% 72.1M 0s\n",
      "   500K .......... .......... .......... .......... .......... 50% 75.0M 0s\n",
      "   550K .......... .......... .......... .......... .......... 55% 71.9M 0s\n",
      "   600K .......... .......... .......... .......... .......... 59% 75.4M 0s\n",
      "   650K .......... .......... .......... .......... .......... 64% 86.9M 0s\n",
      "   700K .......... .......... .......... .......... .......... 68% 84.1M 0s\n",
      "   750K .......... .......... .......... .......... .......... 73% 61.0M 0s\n",
      "   800K .......... .......... .......... .......... .......... 78% 57.8M 0s\n",
      "   850K .......... .......... .......... .......... .......... 82% 77.4M 0s\n",
      "   900K .......... .......... .......... .......... .......... 87% 74.0M 0s\n",
      "   950K .......... .......... .......... .......... .......... 91% 5.23M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 96% 16.0M 0s\n",
      "  1050K .......... .......... .......... .........            100% 46.0M=0.1s\n",
      "\n",
      "2021-11-29 08:26:51 (7.89 MB/s) - './input.txt' saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./ --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "FUTIUDW9Ezyx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\hyeongbin\\anaconda3\\lib\\site-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Q2Y4EMWTEnCo"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "import random\n",
    "import string\n",
    "import time, math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "o10hD8eAE4s0"
   },
   "outputs": [],
   "source": [
    "# hyper parameter \n",
    "EPOCHS = 1000\n",
    "HIDDEN_DIM = 100\n",
    "BATCH_SIZE = 1\n",
    "CHUNK_LEN = 250 # 전체 data가 100만 character 정도여서 전체를 쓰지 않고 일부를 random으로 추출하여 학습하기 위함 \n",
    "NUM_LAYERS = 1  # 강의자료에서는 1개의 layer만을 고려, 2개의 layer라면 rnn 위에 rnn 쌓을 수 있음 \n",
    "EMBEDDING = 70  # word2vec 예제를 보면 one-hot encoding된 input vector를 4차원으로 바꿈, embedding 될 vector를 몇 차원으로 할 것인가 \n",
    "LEARNING_RATE = 0.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "4UFfZrVIFJ0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# character를 직접 정의하지 않고 string module의 printable을 활용하여 들어갈 수 있는 character를 미리 정의 \n",
    "characters = string.printable\n",
    "n_characters = len(characters)\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "1_YtRGWZFaMw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file = unidecode.unidecode(open('./input.txt').read())\n",
    "len_text_file = len(text_file)\n",
    "len_text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "gyzuBNT9Fqhu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ever king so grieved for subjects' woe?\n",
      "Much is your sorrow; mine ten times so much.\n",
      "\n",
      "Son:\n",
      "I'll bear thee hence, where I may weep my fill.\n",
      "\n",
      "Father:\n",
      "These arms of mine shall be thy winding-sheet;\n",
      "My heart, sweet boy, shall be thy sepulchre,\n",
      "For from my\n"
     ]
    }
   ],
   "source": [
    "# 100만개의 data를 전부 사용할 수 없기 때문에 chunk를 활용한다 \n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, len_text_file - CHUNK_LEN)\n",
    "    end_index = start_index + CHUNK_LEN + 1\n",
    "    return text_file[start_index : end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "pc_drwFuFJwh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36, 37, 38, 13, 14])\n"
     ]
    }
   ],
   "source": [
    "# character를 tensor로 바꿔주는 def  \n",
    "# 원래는 one-hot encodding 하였으나 \n",
    "# tensor로 바꾼 후 embedding이 되는 형태로 진행 \n",
    "def character_to_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for char in range(len(string)):\n",
    "        tensor[char] = characters.index(string[char])\n",
    "    return tensor\n",
    "\n",
    "print(character_to_tensor('ABCde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "6OeHNVC2J-6U"
   },
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    chunk = random_chunk()\n",
    "    input = character_to_tensor(chunk[:-1])\n",
    "    target = character_to_tensor(chunk[1:])\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "GA7jZK6fKMwZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([23, 16, 94, 28, 21, 14, 14, 25, 73, 94, 29, 17, 10, 29, 94, 18, 28, 94,\n",
       "         23, 24, 29, 94, 32, 17, 10, 29, 94, 18, 29, 94, 18, 28, 62, 96, 55, 17,\n",
       "         18, 28, 94, 21, 24, 31, 14, 94, 15, 14, 14, 21, 94, 44, 73, 94, 29, 17,\n",
       "         10, 29, 94, 15, 14, 14, 21, 94, 23, 24, 94, 21, 24, 31, 14, 94, 18, 23,\n",
       "         94, 29, 17, 18, 28, 75, 96, 39, 24, 28, 29, 94, 29, 17, 24, 30, 94, 23,\n",
       "         24, 29, 94, 21, 10, 30, 16, 17, 82, 96, 96, 37, 40, 49, 57, 50, 47, 44,\n",
       "         50, 77, 96, 49, 24, 73, 94, 12, 24, 35, 73, 94, 44, 94, 27, 10, 29, 17,\n",
       "         14, 27, 94, 32, 14, 14, 25, 75, 96, 96, 53, 50, 48, 40, 50, 77, 96, 42,\n",
       "         24, 24, 13, 94, 17, 14, 10, 27, 29, 73, 94, 10, 29, 94, 32, 17, 10, 29,\n",
       "         82, 96, 96, 37, 40, 49, 57, 50, 47, 44, 50, 77, 96, 36, 29, 94, 29, 17,\n",
       "         34, 94, 16, 24, 24, 13, 94, 17, 14, 10, 27, 29, 68, 28, 94, 24, 25, 25,\n",
       "         27, 14, 28, 28, 18, 24, 23, 75, 96, 96, 53, 50, 48, 40, 50, 77, 96, 58,\n",
       "         17, 34, 73, 94, 28, 30, 12, 17, 94, 18, 28, 94, 21, 24, 31, 14, 68, 28,\n",
       "         94, 29, 27, 10, 23, 28, 16, 27, 14, 28, 28, 18, 24, 23, 75, 96]),\n",
       " tensor([16, 94, 28, 21, 14, 14, 25, 73, 94, 29, 17, 10, 29, 94, 18, 28, 94, 23,\n",
       "         24, 29, 94, 32, 17, 10, 29, 94, 18, 29, 94, 18, 28, 62, 96, 55, 17, 18,\n",
       "         28, 94, 21, 24, 31, 14, 94, 15, 14, 14, 21, 94, 44, 73, 94, 29, 17, 10,\n",
       "         29, 94, 15, 14, 14, 21, 94, 23, 24, 94, 21, 24, 31, 14, 94, 18, 23, 94,\n",
       "         29, 17, 18, 28, 75, 96, 39, 24, 28, 29, 94, 29, 17, 24, 30, 94, 23, 24,\n",
       "         29, 94, 21, 10, 30, 16, 17, 82, 96, 96, 37, 40, 49, 57, 50, 47, 44, 50,\n",
       "         77, 96, 49, 24, 73, 94, 12, 24, 35, 73, 94, 44, 94, 27, 10, 29, 17, 14,\n",
       "         27, 94, 32, 14, 14, 25, 75, 96, 96, 53, 50, 48, 40, 50, 77, 96, 42, 24,\n",
       "         24, 13, 94, 17, 14, 10, 27, 29, 73, 94, 10, 29, 94, 32, 17, 10, 29, 82,\n",
       "         96, 96, 37, 40, 49, 57, 50, 47, 44, 50, 77, 96, 36, 29, 94, 29, 17, 34,\n",
       "         94, 16, 24, 24, 13, 94, 17, 14, 10, 27, 29, 68, 28, 94, 24, 25, 25, 27,\n",
       "         14, 28, 28, 18, 24, 23, 75, 96, 96, 53, 50, 48, 40, 50, 77, 96, 58, 17,\n",
       "         34, 73, 94, 28, 30, 12, 17, 94, 18, 28, 94, 21, 24, 31, 14, 68, 28, 94,\n",
       "         29, 27, 10, 23, 28, 16, 27, 14, 28, 28, 18, 24, 23, 75, 96, 42]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input - target이 이런 형태로 정의됨 \n",
    "# input은 chuck에서 어떤 지점이 있을텐데 이 지점의 -1까지 해당하는 부분이 input이 되고 \n",
    "# target은 1보다 큰 부분이 target이 된다\n",
    "# 23에서 96까지 input, 23 다음인 16부터 96 다음인 42까지가 target \n",
    "random_training_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPhplF0Ru6a9"
   },
   "source": [
    "### Make RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Gh3P9qxiGnOk"
   },
   "outputs": [],
   "source": [
    "# encoding과 decoding이 포함된 RNN 모델 \n",
    "class EN_RNN_DE(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers):\n",
    "        super(EN_RNN_DE, self).__init__()\n",
    "\n",
    "        # embedding size와 later 수 추가 \n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # embedding 하는 부분 \n",
    "        # encoder layer -> Embedding 함수를 그대로 활용 \n",
    "        # RNN layer -> input, hidden, layer수를 parameter로 받음 \n",
    "        # decoder layer -> linear로 묶어서 hidden을 넣고 마지막으로 output을 얻어내는 형태 \n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.rnn = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "        # encdoer layer에 먼저 input 넣어줌 \n",
    "        # rnn layer을 통해서 hidden state, output 얻게 됨 \n",
    "        # decoder lyaer에서 최종저긴 결과물을 얻게 됨, decoder가 된 output, 해당 layer에는 output vector가 들어감 \n",
    "        # 최종적으로 decoding 된 output 과 hidden return \n",
    "    def forward(self, input, hidden):\n",
    "        en_output = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.rnn(en_output, hidden)\n",
    "        de_output = self.decoder(output.view(1, -1))\n",
    "        return de_output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_size)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "2-P52tmBGnKa"
   },
   "outputs": [],
   "source": [
    "model = EN_RNN_DE(n_characters, EMBEDDING, HIDDEN_DIM, n_characters, NUM_LAYERS)#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "OvU9Ix01MtXu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([1, 1, 100])\n",
      "torch.Size([1, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "# A라는 character를 넣었을 때 어떻게 흘러가는가 \n",
    "# input size \n",
    "# hidden size ~ 마지막은 output size \n",
    "inp = character_to_tensor(\"A\")\n",
    "print(inp.size())\n",
    "hidden = model.init_hidden()\n",
    "print(hidden.size())\n",
    "out,hidden = model(inp,hidden)\n",
    "print(hidden.size())\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "MPc_WL61Bvl2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of EN_RNN_DE(\n",
       "  (encoder): Embedding(100, 70)\n",
       "  (rnn): RNN(70, 100)\n",
       "  (decoder): Linear(in_features=100, out_features=100, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "YEMgXm97Gm4K"
   },
   "outputs": [],
   "source": [
    "optimizer_model = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "MsSNaVDNJnUA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.6142], grad_fn=<DivBackward0>)\n",
      "tensor([2.2460], grad_fn=<DivBackward0>)\n",
      "tensor([2.1213], grad_fn=<DivBackward0>)\n",
      "tensor([2.1741], grad_fn=<DivBackward0>)\n",
      "tensor([2.1136], grad_fn=<DivBackward0>)\n",
      "tensor([2.1410], grad_fn=<DivBackward0>)\n",
      "tensor([1.9719], grad_fn=<DivBackward0>)\n",
      "tensor([1.9750], grad_fn=<DivBackward0>)\n",
      "tensor([2.0312], grad_fn=<DivBackward0>)\n",
      "tensor([2.1560], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# training도 앞선 예제와 비슷하게 흘러감 \n",
    "# chuck를 통해서 구성한 input과 target vector를 정의하고 \n",
    "# hidden에 대한 것을 초기화, loss에 대해 정의 \n",
    "for i in range(EPOCHS):\n",
    "    input, target = random_training_set()\n",
    "    input = input#.to(device)\n",
    "    target = target#.to(device)\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer_model.zero_grad()\n",
    "\n",
    "    for j in range(CHUNK_LEN-1):\n",
    "        x = input[j] # input에 해당하는 tensor(vector)를 가져오고 \n",
    "        y_ = target[j].unsqueeze(0).type(torch.LongTensor) # target에 해당하는 tensor를 가져오고 \n",
    "        y, hidden = model(x, hidden) # model을 돌려서 예측값을 가져온 후 \n",
    "        loss += loss_func(y, y_)     # 실제갑소가 예측값 사이의 loss를 구한 후 \n",
    "\n",
    "    loss.backward() # backward process를 진행 \n",
    "    optimizer_model.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(loss/CHUNK_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "J_lp1RvesKro"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but ther thour same a pure,--\n",
      "How lame unfiar to nibrent kour dead jome of the liers:\n",
      "Wild for frien the lie.\n",
      "\n",
      "LAUTIV:\n",
      "Hould of morit growle my sweety\n",
      "Betsint:\n",
      "Will--\n",
      "\n",
      "AUdIERY:\n",
      "As the vile he kive sir sto my his chandie, felver my brome me hond.\n",
      "\n",
      "LADY URgh:\n",
      "And gistant as it shich wlich sere we massu"
     ]
    }
   ],
   "source": [
    "# b라는 character를 넣었을 때 어떤 text가 generation되는가? \n",
    "start_string = \"b\"\n",
    "\n",
    "input = character_to_tensor(start_string)\n",
    "hidden = model.init_hidden()\n",
    "\n",
    "print(start_string, end=\"\")\n",
    "\n",
    "for i in range(300):\n",
    "    output, hidden = model(input, hidden)\n",
    "\n",
    "    output_dist = output.data.view(-1).div(0.8).exp()\n",
    "    top_i = torch.multinomial(output_dist, 1)[0]\n",
    "    predicted_char = characters[top_i]\n",
    "\n",
    "    print(predicted_char, end=\"\")\n",
    "\n",
    "    input = character_to_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9UZMUNIu_Zh"
   },
   "source": [
    "### Make LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "sYu5wa03vBRu"
   },
   "outputs": [],
   "source": [
    "# 중간 layer에서 RNN을 쓸지 LSTM을 쓸지에 대한 차이만 존재함 \n",
    "# forward def 에서 차이\n",
    "class EN_LSTM_DE(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers):\n",
    "        super(EN_LSTM_DE, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers) # lstm function 활용, 들어가는 변수는 차이 없음 \n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        en_output = self.encoder(input.view(1, -1))                   # input이 encoder를 통과한 결과 \n",
    "        output, (hidden, cell) = self.lstm(en_output, (hidden, cell)) # embedding이 된 input결과와 hidden과 cell이 동시에 () 들어감 \n",
    "        de_output = self.decoder(output.view(1, -1))                  # decoder된 output \n",
    "        return de_output, hidden, cell                                # 최종적으로 decoder된 output과 hidden, cell을 return \n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_size)\n",
    "        cell = torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_size)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "HYPo-9HLvvJF"
   },
   "outputs": [],
   "source": [
    "model_LSTM = EN_LSTM_DE(n_characters, EMBEDDING, HIDDEN_DIM, n_characters, NUM_LAYERS)#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "BG9Kb0auyMfh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of EN_LSTM_DE(\n",
       "  (encoder): Embedding(100, 70)\n",
       "  (lstm): LSTM(70, 100)\n",
       "  (decoder): Linear(in_features=100, out_features=100, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSTM.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7LJ0vVGsKlV"
   },
   "outputs": [],
   "source": [
    "input = character_to_tensor(\"A\")\n",
    "print(input)\n",
    "\n",
    "hidden, cell = model_LSTM.init_hidden()\n",
    "print(hidden.size())\n",
    "\n",
    "output, hidden, cell = model_LSTM(input, hidden, cell)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "1soDd8qbvtNU"
   },
   "outputs": [],
   "source": [
    "optimizer_lstm = torch.optim.Adam(model_LSTM.parameters(), lr = LEARNING_RATE)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "FmsoQgKByvJD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5891], grad_fn=<DivBackward0>)\n",
      "tensor([2.3515], grad_fn=<DivBackward0>)\n",
      "tensor([2.1397], grad_fn=<DivBackward0>)\n",
      "tensor([2.1236], grad_fn=<DivBackward0>)\n",
      "tensor([2.0520], grad_fn=<DivBackward0>)\n",
      "tensor([2.0361], grad_fn=<DivBackward0>)\n",
      "tensor([1.8929], grad_fn=<DivBackward0>)\n",
      "tensor([2.0001], grad_fn=<DivBackward0>)\n",
      "tensor([1.9445], grad_fn=<DivBackward0>)\n",
      "tensor([2.0089], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    input, target = random_training_set()\n",
    "    input = input#.to(device)\n",
    "    target = target#.to(device)\n",
    "    hidden, cell = model_LSTM.init_hidden()\n",
    "\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer_lstm.zero_grad()\n",
    "\n",
    "    for j in range(CHUNK_LEN-1):\n",
    "        x = input[j]\n",
    "        y_ = target[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y, hidden, cell = model_LSTM(x, hidden, cell) # lstm이기 때문에 hidden과 cell이 들어감 \n",
    "        loss += loss_func(y, y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_lstm.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(loss/CHUNK_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "AvJjMxcZvgSU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bit entor for ladies.\n",
      "\n",
      "KING RDWIUS:\n",
      "I seast word and grothers;\n",
      "What shall mosst to; rath to be eart of come, my foursies, Conould are learn to ble wome sirsfed feer of Pepon\n",
      "And for se, a been at learing to his rone the praist to to levaied land fors too to to souston tous of as thou seak have to un "
     ]
    }
   ],
   "source": [
    "# learning rate, epoch을 조절하고 중간 중간 drop out을 함으로써 좀 더 좋은 결과를 얻을 수 있음 \n",
    "start_string = \"b\"\n",
    "\n",
    "input = character_to_tensor(start_string)\n",
    "hidden, cell = model_LSTM.init_hidden()\n",
    "\n",
    "print(start_string, end=\"\")\n",
    "\n",
    "for i in range(300):\n",
    "    output, hidden, cell = model_LSTM(input, hidden, cell)\n",
    "\n",
    "    output_dist = output.data.view(-1).div(0.8).exp()\n",
    "    top_i = torch.multinomial(output_dist, 1)[0]\n",
    "    predicted_char = characters[top_i]\n",
    "\n",
    "    print(predicted_char, end=\"\")\n",
    "\n",
    "    input = character_to_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Week 12.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
